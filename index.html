<html>
	<head>
		<style type="text/css">
			body{font-family: sans-serif;}
			p{display: inline-block;}
			img{display: block;}
			.container{width: 90%;position absolute;margin: auto;}
			.title{position: relative;width: 90%;margin: auto;text-align: center;font-weight: bold;font-size: 32px;padding-top: 0.7cm;}
			.section{position: relative;width: 90%;margin: auto;padding-top: 3cm;}
			.subsection{position: relative; width: 98%;text-align: justify;padding: 10px;}
			.heading{position: relative; width: 98%;text-align: left;font-size: 21px;font-weight: bold;color: DarkBlue;text-decoration: underline;}
			.heading2{position: relative; width: 98%;text-align: left;font-size: 18px;font-weight: bold;color: DimGrey;}
			.text{width: 95%;font-size: 16px;text-align: justify;padding: 10px 0px 10px 0px;}
			.authors{position: relative;width: 80%;margin: auto;padding: 2%;font-style: italic;text-align: center;font-size: 14px;font-weight: bold;}
			.image{width: 95%;font-size: 12px;text-align: left;}
		</style>
	</head>
	<body>
		<div class="container">
			<div class="title">Gender Classification from Speech using Linear Prediction Features</div>

			<div class="authors">

				<!-- Start edit here  -->
				Pranav Totala, Roll No.: 150102051, Branch: ECE;<br> Sanjay Kumar, Roll No.: 150102059, Branch: ECE;&nbsp;&nbsp;
				<br> Saurabh Dhall, Roll No.: 150102060, Branch: ECE; &nbsp; &nbsp;
				<!-- <p>Group Member 4, Roll No.: 15xxxxxxx, Branch: ECE/EEE</p>; &nbsp; &nbsp;
				<p>Group Member 5, Roll No.: 15xxxxxxx, Branch: ECE/EEE</p>; &nbsp; &nbsp;
				Stop edit here -->

			</div>


			<div class="section">
				<div class="heading">Abstract</div>
				<div class="text">

					<!-- Start edit here  -->
					A Gender Classification system has been proposed using Linear Prediction Features. We have identified the voiced frames and then extracted the pitch from the Linear Prediction Residual of these frames for distinguishing male and female voice.<br> Other than pitch, formants and LPCCs were also used to help better classify the given audio sample. SVM was used to classify the voice after the features had been extracted .


				</div>
			</div>

			<div class="section">
				<div class="heading">1. Introduction</div>
				<div class="text">

					<!-- Start edit here  -->
					
					<!-- Stop edit here -->

				</div>

				<div class="subsection">
					<div class="heading2">1.1 Introduction to Problem</div>
					<div class="text">

						<!-- Start edit here  -->
						The  aim  of  this  project  is  to  identify  the  gender  of a  speaker  based  on  the  voice  of  the  speaker  using Linear Prediction Features. Gender-based differences in human speech are partly due to physiological differences such as vocal fold thickness or vocal tract length and partly due to differences in speaking style.<br>
					Since these changes are reflected in the speech signal, we hope to exploit these properties to automatically classify a speaker as male or female. The gender classification is done by using Support Vector Machines (SVM).

						<!-- Stop edit here -->

					</div>
				</div>

				<div class="subsection">
					<div class="heading2">1.2 Figure</div>
					<div class="image">

						<!-- Start edit here  
						Block diagram of the system. All images must be put in a Pictures folder. An example image-->
						<img src="Dsp_project.jpg" alt="Analysis of speech using Matlab" width="700px" height=""/ align="middle">
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading2">1.3 Literature Review</div>
					<div class="text">

						<!-- Start edit here  -->
						What do male and female speech sound different? Gender-based differences in human speech are partly due to physiological differences such as vocal fold thickness or vocal tract length and partly due to differences in speaking style.
Adult men and women typically have different sizes of vocal fold; reflecting the male-female differences in larynx size. The male vocal folds are between 17 mm and 25 mm in length. The female vocal folds are between 12.5 mm and 17.5 mm in length. The difference in vocal folds size between men and women means that they have differently pitched voices. Generally, women have higher pitch than men do.<br><br>
The fundamental frequency/pitch of male voice lies in the range of 85 to 180 Hz while that of the female in the range of 150 to 300 Hz. This discrimination qualifies pitch as an effective feature for gender.<br>
However, there is some overlap for the pitches of high-pitch males and low-pitch females. For increasing classification accuracy, combining pitch and other speech feature is necessary (discussed later).<br>
 
<br>A second important physiological difference is vocal tract length, that is, the distance from the vocal folds to the lips.  All  things  being  equal,  the  longer  the  vocal  tract,  the  lower  the resonant frequencies. The  average  length  of  the  adult  female  vocal  tract is about 14.5  cm,  while  the average  male  vocal tract  is  17  to 18  cm long.<br>
Men, generally speaking, have a larger vocal tract, which essentially gives the resultant voice a lower-sounding timbre.
The vocal tract act as the resonator of the voice. The human vocal tract resonates in different frequency.
Usually it shows four or more resonances. The Formant is the term applied to describe the resonant frequencies of the voice tract. In terms of the Formants, about five formants are required for male voice while four formats for female voice. The formant frequencies of female are higher than that of the male. The difference is very high in the third and fourth formants and least for the first formant. This is mainly due to the length of the voice tract.<br>
Our approach is to extract features that help us distinguish the gender of a given human voice using the physiological differences in the two genders.
Gender-based differences in human speech are partly due to physiological differences such as vocal fold thickness or vocal tract length and partly due to differences in speaking style. We are going to exploit the physiological differences to distinguish between the two genders.

						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading2">1.4 Proposed Approach</div>
					<div class="text">

						<!-- Start edit here  -->
						Describe your approach briefly here.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading2">1.5 Report Organization</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">2. Proposed Approach</div>
				<div class="text">

					<!-- Start edit here  -->
					 
<p>1. Framing: The recorded discrete signal s(n) has always a finite length NTOTAL, but is usually not processed whole due to its quasi-stationary nature. The signal is framed into pieces of length N much less than NTOTAL samples. The vocal tract is not able to change its shape faster than fifty times per second, which gives us a period of 20 milliseconds during which the signal can be assumed to be stationary. The length N of the frames is based on a compromise between time and frequency resolution. An overlapping of the individual frames is used to increase precision of the recognition process.</p>
<br><p>2. Windowing: Before further processing, the individual frames are windowed. We have used a standard hamming window.
where sw(n) is the windowed signal, s(n) is the original signal N samples long, and w(n) is the window itself.</p>
<br><p>3. Pre-Emphasis: Pre-emphasis is processing of the input signal by a low order digital FIR filter so as to flatten spectrally the input signal in favor of vocal tract parameters. It makes the signal less susceptible to later finite precision effects. This filter is usually the first order FIR filter defined as sp(n)=s(n)-a.s(n-1) Where a is a pre-emphasis coefficient lying usually in an interval of (0.9 to1), s(n) is the original signal, and sp(n) is a pre-emphasized signal.</p>
 
<br>Speech signal can be classified into voiced, unvoiced and silence regions. The near periodic vibration of vocal folds is excitation for the production of voiced speech. The random like excitation is present for unvoiced speech. There is no excitation during silence region. Majority of speech regions are voiced in nature that include vowels, semivowels and other voiced components. The voiced regions looks like a near periodic signal in the time domain representation. In a short term, we may treat the voiced speech segments to be periodic for all practical analysis and processing.
We have used Zero Crossing Rate, Pitch and a Magnitude Sum Function to classify the frames as voiced using simple thresholds, which were functions of these features themselves.
Zero Crossing Rate is the rate of sign-changes along a signal, i.e., the rate at which the signal changes from positive to negative or back.
Pitch is the fundamental frequency of the input excitation to our vocal tract.
<br>Magnitude Sum Function sums the modulus of all the samples in our frame.
After identifying the voiced frames, we have primarily worked on these frames to calculate the pitch of the human voice.

					<!-- Stop edit here -->

				</div>
			</div>

			<div class="section">
				<div class="heading">3. Experiments &amp; Results</div>
				<div class="subsection">
					<div class="heading2">3.1 Dataset Description</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading2">3.2 Discussion</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

			<div class="section">
				<div class="heading">4. Conclusions</div>
				<div class="subsection">
					<div class="heading2">4.1 Summary</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
				<div class="subsection">
					<div class="heading2">4.2 Future Extensions</div>
					<div class="text">

						<!-- Start edit here  -->
						Write something here.
						<!-- Stop edit here -->

					</div>
				</div>
			</div>

		</div>
	</body>
</html>
